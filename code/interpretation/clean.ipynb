{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d72ea18-ab92-4417-8a84-56b750715200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append('code')\n",
    "sys.path.append(\"/jet/home/azhang19/stat 214/stat-214-lab3-group6/code\")\n",
    "\n",
    "from BERT.data import TextDataset\n",
    "from finetune_bert_utils import get_sliding_window_embeddings, aggregate_embeddings, downsample_word_vectors_torch, load_fmri_data, get_fmri_data\n",
    "\n",
    "# Define the base path for data access\n",
    "data_path = '/ocean/projects/mth240012p/shared/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbaf7055-7103-4076-a074-849b840cbff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_path}/raw_text.pkl', 'rb') as file:\n",
    "    wordseqs = pickle.load(file)\n",
    "\n",
    "stories = [i[:-4] for i in os.listdir(f'{data_path}/subject2')]\n",
    "\n",
    "train_stories, temp_stories = train_test_split(stories, train_size=0.6, random_state=214)\n",
    "val_stories, test_stories = train_test_split(temp_stories, train_size=0.5, random_state=214)\n",
    "\n",
    "story_name_to_idx = {story: i for i, story in enumerate(stories)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df151a6c-3b89-4c4b-b286-fc2de23e3935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_values(score, prefix, subj):    \n",
    "    path = f\"{score}_{prefix}_subj{subj}.pkl\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        values = pickle.load(f)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bda337c7-9c7d-4056-af8a-f9ed1c04ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def story_to_df(story):\n",
    "    chunks = wordseqs[story].chunks()\n",
    "    valid_chunks = chunks[5:-10]\n",
    "\n",
    "    chunk_ids = []\n",
    "    word_ids = []\n",
    "    words = []\n",
    "    \n",
    "    for t, chunk in enumerate(valid_chunks):\n",
    "        i = 0\n",
    "        if chunk.size == 0:\n",
    "            words.append(None)\n",
    "            word_ids.append(i+1)\n",
    "            chunk_ids.append(t+1)\n",
    "        else:\n",
    "            for word in chunk:\n",
    "                word = word if word else None\n",
    "                words.append(word)\n",
    "                word_ids.append(i+1)\n",
    "                chunk_ids.append(t+1)\n",
    "                i += 1\n",
    "\n",
    "    df = pd.DataFrame({\"chunk_id\": chunk_ids, \"word_id\": word_ids, \"word\": words})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c116810-9699-43d3-b244-357d0b73666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_to_df(vals, story, av=True):\n",
    "    vals = np.abs(vals) if av else vals\n",
    "    mean_vals = np.mean(vals, axis=1)\n",
    "    \n",
    "    columns = [f\"v_{i}\" for i in range(1, mean_vals.shape[1]+1)]\n",
    "    df_values = pd.DataFrame(mean_vals, columns=columns)\n",
    "    df_values[\"chunk_id\"] = df_values.index + 1\n",
    "\n",
    "    df_story = story_to_df(story)\n",
    "\n",
    "    assert df_values[\"chunk_id\"].max() == df_story[\"chunk_id\"].max(), f\"chunk_id mismatch: {df_values[\"chunk_id\"].max()} vs. {df_story[\"chunk_id\"].max()}\"\n",
    "    \n",
    "    df = pd.merge(df_values, df_story, on='chunk_id', how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45aad351-1035-4924-9088-a122858b72fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_stories = test_stories[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2f3732af-b7f0-467c-9afc-a059b10916cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved lime_buck_subj2.csv\n",
      "Saved lime_buck_subj3.csv\n",
      "Saved lime_laws_subj2.csv\n",
      "Saved lime_laws_subj3.csv\n"
     ]
    }
   ],
   "source": [
    "for story in select_stories:\n",
    "    prefix = story[:4]\n",
    "    for subj in [2,3]:\n",
    "        score = \"lime\" # \"shap\" or \"lime\"\n",
    "        vals = read_scores(score, prefix, subj)\n",
    "        df = scores_to_df(vals, story)\n",
    "        path_df = f\"{score}_{prefix}_subj{subj}.csv\"\n",
    "        df.to_csv(path_df, index=False)\n",
    "        print(f\"Saved {path_df}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
