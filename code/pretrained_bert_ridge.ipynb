{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('code')\n",
    "sys.path.append(\"/jet/home/azhang19/stat 214/stat-214-lab3-group6/code\")\n",
    "\n",
    "from BERT.data import TextDataset\n",
    "from finetune_bert_utils import get_sliding_window_embeddings, aggregate_embeddings, downsample_word_vectors_torch, load_fmri_data, get_fmri_data\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define the base path for data access\n",
    "data_path = '/ocean/projects/mth240012p/shared/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_76929/1482417774.py:3: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  wordseqs = pickle.load(file) # wordseqs is expected to be a dictionary: {story_id: WordSequenceObject}\n"
     ]
    }
   ],
   "source": [
    "# %% Load preprocessed word sequences (likely includes words and their timings)\n",
    "with open(f'{data_path}/raw_text.pkl', 'rb') as file:\n",
    "    wordseqs = pickle.load(file) # wordseqs is expected to be a dictionary: {story_id: WordSequenceObject}\n",
    "\n",
    "# %% Get list of story identifiers and split into training and testing sets\n",
    "# Assumes story data for 'subject2' exists and filenames are story IDs + '.npy'\n",
    "stories = [i[:-4] for i in os.listdir(f'{data_path}/subject2')] # Extract story IDs from filenames\n",
    "# Split stories into train and test sets with a fixed random state for reproducibility\n",
    "\n",
    "\n",
    "# First, use 60% for training and 40% for the remaining data.\n",
    "train_stories, temp_stories = train_test_split(stories, train_size=0.6, random_state=214)\n",
    "# Then split the remaining 40% equally to get 20% validation and 20% test.\n",
    "val_stories, test_stories = train_test_split(temp_stories, train_size=0.5, random_state=214)\n",
    "\n",
    "story_name_to_idx = {story: i for i, story in enumerate(stories)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "base_model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = [\" \".join(wordseqs[i].data).strip() for i in train_stories]\n",
    "train_dataset = TextDataset(train_text, tokenizer, max_len=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_range = (5, -10)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "embeddings = {}\n",
    "\n",
    "texts = []\n",
    "\n",
    "for story in stories:\n",
    "    words = wordseqs[story].data\n",
    "    texts.append(\" \".join(words).strip())\n",
    "    tokens = tokenizer(words, add_special_tokens=False, truncation=False, max_length=sys.maxsize)['input_ids']\n",
    "    token_per_word = [len(i) for i in tokens]\n",
    "tokenlized_stories = tokenizer(texts, add_special_tokens=False, padding=\"longest\", truncation=False, max_length=sys.maxsize,\n",
    "                               return_token_type_ids=False, return_tensors=\"pt\")\n",
    "input_ids = tokenlized_stories[\"input_ids\"].to(device)\n",
    "attention_mask = tokenlized_stories[\"attention_mask\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(current_stories):\n",
    "    idx = [story_name_to_idx[story] for story in current_stories]\n",
    "    embeddings = get_sliding_window_embeddings(base_model, input_ids[idx], attention_mask[idx])\n",
    "\n",
    "    features = {}\n",
    "    for i, story in enumerate(current_stories):\n",
    "        words = wordseqs[story].data\n",
    "        tokens = tokenizer(words, add_special_tokens=False, truncation=False, max_length=sys.maxsize)['input_ids']\n",
    "        token_per_word = [len(i) for i in tokens]\n",
    "        story_embeddings = embeddings[i]\n",
    "        word_embeddings = []\n",
    "        start = 0\n",
    "        for i in token_per_word:\n",
    "            end = start + i\n",
    "            if i != 0:\n",
    "                word_embedding = story_embeddings[start:end].mean(dim=0)\n",
    "            else:\n",
    "                word_embedding = torch.zeros(story_embeddings.size(1), device=device)\n",
    "            word_embeddings.append(word_embedding)\n",
    "            start = end\n",
    "        \n",
    "        features[story] = torch.stack(word_embeddings)#.cpu().numpy()\n",
    "\n",
    "    features = downsample_word_vectors_torch(current_stories, features, wordseqs)\n",
    "    for story in current_stories:\n",
    "        features[story] = features[story][trim_range[0]:trim_range[1]]\n",
    "\n",
    "    aggregated_features = aggregate_embeddings(features, current_stories)\n",
    "    return aggregated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_data = load_fmri_data(stories, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(classifiers, sample_stories):\n",
    "    with torch.inference_mode():\n",
    "        features = forward_pass(sample_stories)\n",
    "    features = features.clone()\n",
    "    pred_fmri = {}\n",
    "    loss = []\n",
    "    current_fmri = get_fmri_data(sample_stories, fmri_data)\n",
    "    for subj in fmri_data.keys():\n",
    "        pred_fmri[subj] = classifiers[subj](features)\n",
    "        obj = torch.from_numpy(current_fmri[subj]).float().to(device)\n",
    "        # Handle NaN values in obj\n",
    "        obj = torch.nan_to_num(obj, nan=0.0)\n",
    "        loss.append(nn.functional.mse_loss(pred_fmri[subj], obj))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(classifiers, sample_stories):\n",
    "    with torch.inference_mode():\n",
    "        features = forward_pass(sample_stories)\n",
    "    features = features.clone()\n",
    "    loss = get_loss(classifiers, sample_stories)\n",
    "    loss_for_backprop = loss[0] + loss[1]\n",
    "\n",
    "    optim.zero_grad(set_to_none=True)\n",
    "    loss_for_backprop.backward()\n",
    "    optim.step()\n",
    "    return loss_for_backprop.item(), loss[0].item(), loss[1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "loss_record = np.zeros((epochs, 2, 2))\n",
    "best_loss = np.zeros(2) + 1e9\n",
    "best_classifiers = {'subject2': None, 'subject3': None}\n",
    "\n",
    "#sample_stories = random.sample(stories, 3)\n",
    "sample_stories = train_stories\n",
    "#features = forward_pass(sample_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 1e-2\n",
    "classifiers = {'subject2': nn.Linear(768, 94251, device=device), 'subject3': nn.Linear(768, 95556, device=device)}\n",
    "optim = torch.optim.AdamW(itertools.chain(*[i.parameters() for i in classifiers.values()]), lr=2e-3, weight_decay=weight_decay, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 2.9351, 2.9298, Val Loss: 3.0720, 3.0702\n",
      "New best validation loss for subject2: 3.0720\n",
      "New best validation loss for subject3: 3.0702\n",
      "Epoch 2/100, Loss: 3.1365, 3.1355, Val Loss: 2.3179, 2.3153\n",
      "New best validation loss for subject2: 2.3179\n",
      "New best validation loss for subject3: 2.3153\n",
      "Epoch 3/100, Loss: 2.3588, 2.3569, Val Loss: 2.2215, 2.2183\n",
      "New best validation loss for subject2: 2.2215\n",
      "New best validation loss for subject3: 2.2183\n",
      "Epoch 4/100, Loss: 2.2589, 2.2562, Val Loss: 2.3439, 2.3405\n",
      "Epoch 5/100, Loss: 2.3842, 2.3811, Val Loss: 2.0447, 2.0420\n",
      "New best validation loss for subject2: 2.0447\n",
      "New best validation loss for subject3: 2.0420\n",
      "Epoch 6/100, Loss: 2.0787, 2.0762, Val Loss: 1.7070, 1.7059\n",
      "New best validation loss for subject2: 1.7070\n",
      "New best validation loss for subject3: 1.7059\n",
      "Epoch 7/100, Loss: 1.7325, 1.7314, Val Loss: 1.6964, 1.6963\n",
      "New best validation loss for subject2: 1.6964\n",
      "New best validation loss for subject3: 1.6963\n",
      "Epoch 8/100, Loss: 1.7186, 1.7185, Val Loss: 1.8615, 1.8603\n",
      "Epoch 9/100, Loss: 1.8835, 1.8824, Val Loss: 1.8430, 1.8398\n",
      "Epoch 10/100, Loss: 1.8615, 1.8585, Val Loss: 1.6341, 1.6306\n",
      "New best validation loss for subject2: 1.6341\n",
      "New best validation loss for subject3: 1.6306\n",
      "Epoch 11/100, Loss: 1.6464, 1.6431, Val Loss: 1.4779, 1.4760\n",
      "New best validation loss for subject2: 1.4779\n",
      "New best validation loss for subject3: 1.4760\n",
      "Epoch 12/100, Loss: 1.4858, 1.4842, Val Loss: 1.5022, 1.5015\n",
      "Epoch 13/100, Loss: 1.5101, 1.5096, Val Loss: 1.5881, 1.5869\n",
      "Epoch 14/100, Loss: 1.5972, 1.5961, Val Loss: 1.5700, 1.5678\n",
      "Epoch 15/100, Loss: 1.5780, 1.5758, Val Loss: 1.4553, 1.4532\n",
      "New best validation loss for subject2: 1.4553\n",
      "New best validation loss for subject3: 1.4532\n",
      "Epoch 16/100, Loss: 1.4600, 1.4578, Val Loss: 1.3701, 1.3687\n",
      "New best validation loss for subject2: 1.3701\n",
      "New best validation loss for subject3: 1.3687\n",
      "Epoch 17/100, Loss: 1.3717, 1.3702, Val Loss: 1.3800, 1.3787\n",
      "Epoch 18/100, Loss: 1.3803, 1.3789, Val Loss: 1.4230, 1.4212\n",
      "Epoch 19/100, Loss: 1.4228, 1.4209, Val Loss: 1.4125, 1.4104\n",
      "Epoch 20/100, Loss: 1.4110, 1.4088, Val Loss: 1.3499, 1.3481\n",
      "New best validation loss for subject2: 1.3499\n",
      "New best validation loss for subject3: 1.3481\n",
      "Epoch 21/100, Loss: 1.3464, 1.3446, Val Loss: 1.3021, 1.3008\n",
      "New best validation loss for subject2: 1.3021\n",
      "New best validation loss for subject3: 1.3008\n",
      "Epoch 22/100, Loss: 1.2971, 1.2958, Val Loss: 1.3034, 1.3020\n",
      "Epoch 23/100, Loss: 1.2980, 1.2967, Val Loss: 1.3202, 1.3183\n",
      "Epoch 24/100, Loss: 1.3146, 1.3126, Val Loss: 1.3098, 1.3076\n",
      "Epoch 25/100, Loss: 1.3032, 1.3009, Val Loss: 1.2766, 1.2748\n",
      "New best validation loss for subject2: 1.2766\n",
      "New best validation loss for subject3: 1.2748\n",
      "Epoch 26/100, Loss: 1.2683, 1.2664, Val Loss: 1.2535, 1.2523\n",
      "New best validation loss for subject2: 1.2535\n",
      "New best validation loss for subject3: 1.2523\n",
      "Epoch 27/100, Loss: 1.2438, 1.2424, Val Loss: 1.2519, 1.2506\n",
      "New best validation loss for subject2: 1.2519\n",
      "New best validation loss for subject3: 1.2506\n",
      "Epoch 28/100, Loss: 1.2412, 1.2399, Val Loss: 1.2537, 1.2518\n",
      "Epoch 29/100, Loss: 1.2423, 1.2404, Val Loss: 1.2439, 1.2417\n",
      "New best validation loss for subject2: 1.2439\n",
      "New best validation loss for subject3: 1.2417\n",
      "Epoch 30/100, Loss: 1.2319, 1.2297, Val Loss: 1.2282, 1.2263\n",
      "New best validation loss for subject2: 1.2282\n",
      "New best validation loss for subject3: 1.2263\n",
      "Epoch 31/100, Loss: 1.2156, 1.2137, Val Loss: 1.2176, 1.2161\n",
      "New best validation loss for subject2: 1.2176\n",
      "New best validation loss for subject3: 1.2161\n",
      "Epoch 32/100, Loss: 1.2045, 1.2030, Val Loss: 1.2126, 1.2110\n",
      "New best validation loss for subject2: 1.2126\n",
      "New best validation loss for subject3: 1.2110\n",
      "Epoch 33/100, Loss: 1.1990, 1.1974, Val Loss: 1.2077, 1.2059\n",
      "New best validation loss for subject2: 1.2077\n",
      "New best validation loss for subject3: 1.2059\n",
      "Epoch 34/100, Loss: 1.1935, 1.1916, Val Loss: 1.2016, 1.1996\n",
      "New best validation loss for subject2: 1.2016\n",
      "New best validation loss for subject3: 1.1996\n",
      "Epoch 35/100, Loss: 1.1865, 1.1845, Val Loss: 1.1954, 1.1935\n",
      "New best validation loss for subject2: 1.1954\n",
      "New best validation loss for subject3: 1.1935\n",
      "Epoch 36/100, Loss: 1.1795, 1.1776, Val Loss: 1.1889, 1.1872\n",
      "New best validation loss for subject2: 1.1889\n",
      "New best validation loss for subject3: 1.1872\n",
      "Epoch 37/100, Loss: 1.1723, 1.1706, Val Loss: 1.1822, 1.1805\n",
      "New best validation loss for subject2: 1.1822\n",
      "New best validation loss for subject3: 1.1805\n",
      "Epoch 38/100, Loss: 1.1650, 1.1632, Val Loss: 1.1772, 1.1753\n",
      "New best validation loss for subject2: 1.1772\n",
      "New best validation loss for subject3: 1.1753\n",
      "Epoch 39/100, Loss: 1.1595, 1.1575, Val Loss: 1.1743, 1.1724\n",
      "New best validation loss for subject2: 1.1743\n",
      "New best validation loss for subject3: 1.1724\n",
      "Epoch 40/100, Loss: 1.1561, 1.1542, Val Loss: 1.1705, 1.1687\n",
      "New best validation loss for subject2: 1.1705\n",
      "New best validation loss for subject3: 1.1687\n",
      "Epoch 41/100, Loss: 1.1519, 1.1500, Val Loss: 1.1644, 1.1626\n",
      "New best validation loss for subject2: 1.1644\n",
      "New best validation loss for subject3: 1.1626\n",
      "Epoch 42/100, Loss: 1.1452, 1.1433, Val Loss: 1.1588, 1.1569\n",
      "New best validation loss for subject2: 1.1588\n",
      "New best validation loss for subject3: 1.1569\n",
      "Epoch 43/100, Loss: 1.1391, 1.1372, Val Loss: 1.1564, 1.1545\n",
      "New best validation loss for subject2: 1.1564\n",
      "New best validation loss for subject3: 1.1545\n",
      "Epoch 44/100, Loss: 1.1362, 1.1342, Val Loss: 1.1546, 1.1528\n",
      "New best validation loss for subject2: 1.1546\n",
      "New best validation loss for subject3: 1.1528\n",
      "Epoch 45/100, Loss: 1.1340, 1.1320, Val Loss: 1.1505, 1.1486\n",
      "New best validation loss for subject2: 1.1505\n",
      "New best validation loss for subject3: 1.1486\n",
      "Epoch 46/100, Loss: 1.1293, 1.1274, Val Loss: 1.1454, 1.1435\n",
      "New best validation loss for subject2: 1.1454\n",
      "New best validation loss for subject3: 1.1435\n",
      "Epoch 47/100, Loss: 1.1237, 1.1217, Val Loss: 1.1424, 1.1404\n",
      "New best validation loss for subject2: 1.1424\n",
      "New best validation loss for subject3: 1.1404\n",
      "Epoch 48/100, Loss: 1.1203, 1.1183, Val Loss: 1.1409, 1.1390\n",
      "New best validation loss for subject2: 1.1409\n",
      "New best validation loss for subject3: 1.1390\n",
      "Epoch 49/100, Loss: 1.1185, 1.1165, Val Loss: 1.1380, 1.1361\n",
      "New best validation loss for subject2: 1.1380\n",
      "New best validation loss for subject3: 1.1361\n",
      "Epoch 50/100, Loss: 1.1153, 1.1133, Val Loss: 1.1341, 1.1322\n",
      "New best validation loss for subject2: 1.1341\n",
      "New best validation loss for subject3: 1.1322\n",
      "Epoch 51/100, Loss: 1.1109, 1.1089, Val Loss: 1.1312, 1.1293\n",
      "New best validation loss for subject2: 1.1312\n",
      "New best validation loss for subject3: 1.1293\n",
      "Epoch 52/100, Loss: 1.1076, 1.1056, Val Loss: 1.1295, 1.1276\n",
      "New best validation loss for subject2: 1.1295\n",
      "New best validation loss for subject3: 1.1276\n",
      "Epoch 53/100, Loss: 1.1056, 1.1035, Val Loss: 1.1274, 1.1255\n",
      "New best validation loss for subject2: 1.1274\n",
      "New best validation loss for subject3: 1.1255\n",
      "Epoch 54/100, Loss: 1.1030, 1.1010, Val Loss: 1.1244, 1.1226\n",
      "New best validation loss for subject2: 1.1244\n",
      "New best validation loss for subject3: 1.1226\n",
      "Epoch 55/100, Loss: 1.0997, 1.0977, Val Loss: 1.1220, 1.1201\n",
      "New best validation loss for subject2: 1.1220\n",
      "New best validation loss for subject3: 1.1201\n",
      "Epoch 56/100, Loss: 1.0969, 1.0948, Val Loss: 1.1201, 1.1182\n",
      "New best validation loss for subject2: 1.1201\n",
      "New best validation loss for subject3: 1.1182\n",
      "Epoch 57/100, Loss: 1.0948, 1.0927, Val Loss: 1.1182, 1.1162\n",
      "New best validation loss for subject2: 1.1182\n",
      "New best validation loss for subject3: 1.1162\n",
      "Epoch 58/100, Loss: 1.0924, 1.0903, Val Loss: 1.1159, 1.1140\n",
      "New best validation loss for subject2: 1.1159\n",
      "New best validation loss for subject3: 1.1140\n",
      "Epoch 59/100, Loss: 1.0899, 1.0878, Val Loss: 1.1140, 1.1121\n",
      "New best validation loss for subject2: 1.1140\n",
      "New best validation loss for subject3: 1.1121\n",
      "Epoch 60/100, Loss: 1.0876, 1.0855, Val Loss: 1.1122, 1.1103\n",
      "New best validation loss for subject2: 1.1122\n",
      "New best validation loss for subject3: 1.1103\n",
      "Epoch 61/100, Loss: 1.0855, 1.0833, Val Loss: 1.1103, 1.1084\n",
      "New best validation loss for subject2: 1.1103\n",
      "New best validation loss for subject3: 1.1084\n",
      "Epoch 62/100, Loss: 1.0833, 1.0811, Val Loss: 1.1085, 1.1066\n",
      "New best validation loss for subject2: 1.1085\n",
      "New best validation loss for subject3: 1.1066\n",
      "Epoch 63/100, Loss: 1.0812, 1.0790, Val Loss: 1.1068, 1.1050\n",
      "New best validation loss for subject2: 1.1068\n",
      "New best validation loss for subject3: 1.1050\n",
      "Epoch 64/100, Loss: 1.0792, 1.0771, Val Loss: 1.1052, 1.1033\n",
      "New best validation loss for subject2: 1.1052\n",
      "New best validation loss for subject3: 1.1033\n",
      "Epoch 65/100, Loss: 1.0773, 1.0751, Val Loss: 1.1035, 1.1016\n",
      "New best validation loss for subject2: 1.1035\n",
      "New best validation loss for subject3: 1.1016\n",
      "Epoch 66/100, Loss: 1.0752, 1.0731, Val Loss: 1.1020, 1.1001\n",
      "New best validation loss for subject2: 1.1020\n",
      "New best validation loss for subject3: 1.1001\n",
      "Epoch 67/100, Loss: 1.0734, 1.0713, Val Loss: 1.1005, 1.0987\n",
      "New best validation loss for subject2: 1.1005\n",
      "New best validation loss for subject3: 1.0987\n",
      "Epoch 68/100, Loss: 1.0717, 1.0696, Val Loss: 1.0990, 1.0971\n",
      "New best validation loss for subject2: 1.0990\n",
      "New best validation loss for subject3: 1.0971\n",
      "Epoch 69/100, Loss: 1.0699, 1.0677, Val Loss: 1.0975, 1.0956\n",
      "New best validation loss for subject2: 1.0975\n",
      "New best validation loss for subject3: 1.0956\n",
      "Epoch 70/100, Loss: 1.0681, 1.0659, Val Loss: 1.0961, 1.0943\n",
      "New best validation loss for subject2: 1.0961\n",
      "New best validation loss for subject3: 1.0943\n",
      "Epoch 71/100, Loss: 1.0665, 1.0643, Val Loss: 1.0948, 1.0930\n",
      "New best validation loss for subject2: 1.0948\n",
      "New best validation loss for subject3: 1.0930\n",
      "Epoch 72/100, Loss: 1.0649, 1.0627, Val Loss: 1.0934, 1.0915\n",
      "New best validation loss for subject2: 1.0934\n",
      "New best validation loss for subject3: 1.0915\n",
      "Epoch 73/100, Loss: 1.0633, 1.0611, Val Loss: 1.0921, 1.0902\n",
      "New best validation loss for subject2: 1.0921\n",
      "New best validation loss for subject3: 1.0902\n",
      "Epoch 74/100, Loss: 1.0617, 1.0594, Val Loss: 1.0909, 1.0890\n",
      "New best validation loss for subject2: 1.0909\n",
      "New best validation loss for subject3: 1.0890\n",
      "Epoch 75/100, Loss: 1.0602, 1.0580, Val Loss: 1.0897, 1.0878\n",
      "New best validation loss for subject2: 1.0897\n",
      "New best validation loss for subject3: 1.0878\n",
      "Epoch 76/100, Loss: 1.0587, 1.0565, Val Loss: 1.0884, 1.0866\n",
      "New best validation loss for subject2: 1.0884\n",
      "New best validation loss for subject3: 1.0866\n",
      "Epoch 77/100, Loss: 1.0572, 1.0550, Val Loss: 1.0873, 1.0854\n",
      "New best validation loss for subject2: 1.0873\n",
      "New best validation loss for subject3: 1.0854\n",
      "Epoch 78/100, Loss: 1.0558, 1.0535, Val Loss: 1.0862, 1.0843\n",
      "New best validation loss for subject2: 1.0862\n",
      "New best validation loss for subject3: 1.0843\n",
      "Epoch 79/100, Loss: 1.0544, 1.0522, Val Loss: 1.0850, 1.0831\n",
      "New best validation loss for subject2: 1.0850\n",
      "New best validation loss for subject3: 1.0831\n",
      "Epoch 80/100, Loss: 1.0530, 1.0508, Val Loss: 1.0839, 1.0820\n",
      "New best validation loss for subject2: 1.0839\n",
      "New best validation loss for subject3: 1.0820\n",
      "Epoch 81/100, Loss: 1.0517, 1.0494, Val Loss: 1.0828, 1.0809\n",
      "New best validation loss for subject2: 1.0828\n",
      "New best validation loss for subject3: 1.0809\n",
      "Epoch 82/100, Loss: 1.0504, 1.0481, Val Loss: 1.0818, 1.0799\n",
      "New best validation loss for subject2: 1.0818\n",
      "New best validation loss for subject3: 1.0799\n",
      "Epoch 83/100, Loss: 1.0491, 1.0468, Val Loss: 1.0808, 1.0789\n",
      "New best validation loss for subject2: 1.0808\n",
      "New best validation loss for subject3: 1.0789\n",
      "Epoch 84/100, Loss: 1.0478, 1.0455, Val Loss: 1.0798, 1.0779\n",
      "New best validation loss for subject2: 1.0798\n",
      "New best validation loss for subject3: 1.0779\n",
      "Epoch 85/100, Loss: 1.0466, 1.0443, Val Loss: 1.0788, 1.0769\n",
      "New best validation loss for subject2: 1.0788\n",
      "New best validation loss for subject3: 1.0769\n",
      "Epoch 86/100, Loss: 1.0453, 1.0431, Val Loss: 1.0778, 1.0759\n",
      "New best validation loss for subject2: 1.0778\n",
      "New best validation loss for subject3: 1.0759\n",
      "Epoch 87/100, Loss: 1.0441, 1.0419, Val Loss: 1.0769, 1.0749\n",
      "New best validation loss for subject2: 1.0769\n",
      "New best validation loss for subject3: 1.0749\n",
      "Epoch 88/100, Loss: 1.0430, 1.0407, Val Loss: 1.0759, 1.0740\n",
      "New best validation loss for subject2: 1.0759\n",
      "New best validation loss for subject3: 1.0740\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     _, loss_subject2_train, loss_subject3_train = \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifiers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_stories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m      4\u001b[39m         loss_subject2_val, loss_subject3_val = get_loss(classifiers, val_stories)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtrain_step\u001b[39m\u001b[34m(classifiers, sample_stories)\u001b[39m\n\u001b[32m      3\u001b[39m     features = forward_pass(sample_stories)\n\u001b[32m      4\u001b[39m features = features.clone()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m loss = \u001b[43mget_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifiers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_stories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m loss_for_backprop = loss[\u001b[32m0\u001b[39m] + loss[\u001b[32m1\u001b[39m]\n\u001b[32m      8\u001b[39m optim.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mget_loss\u001b[39m\u001b[34m(classifiers, sample_stories)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_loss\u001b[39m(classifiers, sample_stories):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode():\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m         features = \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_stories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     features = features.clone()\n\u001b[32m      5\u001b[39m     pred_fmri = {}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(current_stories)\u001b[39m\n\u001b[32m     20\u001b[39m         start = end\n\u001b[32m     22\u001b[39m     features[story] = torch.stack(word_embeddings)\u001b[38;5;66;03m#.cpu().numpy()\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m features = \u001b[43mdownsample_word_vectors_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_stories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwordseqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m story \u001b[38;5;129;01min\u001b[39;00m current_stories:\n\u001b[32m     26\u001b[39m     features[story] = features[story][trim_range[\u001b[32m0\u001b[39m]:trim_range[\u001b[32m1\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/stat 214/stat-214-lab3-group6/code/finetune_bert_utils.py:262\u001b[39m, in \u001b[36mdownsample_word_vectors_torch\u001b[39m\u001b[34m(stories, word_vectors, wordseqs, device_str)\u001b[39m\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    260\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwordseqs.tr_times for story \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m must be np.ndarray or torch.Tensor\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     downsampled_semanticseqs_torch[story] = \u001b[43mlanczosinterp2D_torch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwv_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_times_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtr_times_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m downsampled_semanticseqs_torch\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/stat 214/stat-214-lab3-group6/code/finetune_bert_utils.py:191\u001b[39m, in \u001b[36mlanczosinterp2D_torch\u001b[39m\u001b[34m(data, oldtime, newtime, window, cutoff_mult, rectify)\u001b[39m\n\u001b[32m    189\u001b[39m     time_diffs = newtime_t[ndi] - oldtime_t \u001b[38;5;66;03m# Operates on time_dtype tensors\u001b[39;00m\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# lanczosfun_torch will use dtype of time_diffs or promote to float32 if time_diffs is int\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     sincmat[ndi, :] = \u001b[43mlanczosfun_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_diffs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m)\u001b[49m.to(sincmat_dtype)\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Ensure data is float for matmul with sincmat\u001b[39;00m\n\u001b[32m    194\u001b[39m data_float = data.to(sincmat_dtype) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m data.dtype != sincmat_dtype \u001b[38;5;28;01melse\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/stat 214/stat-214-lab3-group6/code/finetune_bert_utils.py:115\u001b[39m, in \u001b[36mlanczosfun_torch\u001b[39m\u001b[34m(cutoff, t, window)\u001b[39m\n\u001b[32m    112\u001b[39m nonzero_mask = t_scaled != \u001b[32m0\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# Calculate for non-zero t_scaled\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnonzero_mask\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    116\u001b[39m     t_scaled_nz = t_scaled[nonzero_mask]\n\u001b[32m    117\u001b[39m     numerator_nz = window_float * torch.sin(pi_val * t_scaled_nz) * \\\n\u001b[32m    118\u001b[39m                    torch.sin(pi_val * t_scaled_nz / window_float)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    _, loss_subject2_train, loss_subject3_train = train_step(classifiers, sample_stories)\n",
    "    with torch.no_grad():\n",
    "        loss_subject2_val, loss_subject3_val = get_loss(classifiers, val_stories)\n",
    "        loss_subject2_val, loss_subject3_val = loss_subject2_val.item(), loss_subject3_val.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss_subject2_train:.4f}, {loss_subject3_train:.4f}, Val Loss: {loss_subject2_val:.4f}, {loss_subject3_val:.4f}\")\n",
    "    loss_record[epoch, 0, 0] = loss_subject2_train\n",
    "    loss_record[epoch, 0, 1] = loss_subject2_val\n",
    "    loss_record[epoch, 1, 0] = loss_subject3_train\n",
    "    loss_record[epoch, 1, 1] = loss_subject3_val\n",
    "    if loss_subject2_val < best_loss[0]:\n",
    "        print(f\"New best validation loss for subject2: {loss_subject2_val:.4f}\")\n",
    "        best_loss[0] = loss_subject2_val\n",
    "        best_classifiers['subject2'] = copy.deepcopy(classifiers['subject2'])\n",
    "    if loss_subject3_val < best_loss[1]:\n",
    "        print(f\"New best validation loss for subject3: {loss_subject3_val:.4f}\")\n",
    "        best_loss[1] = loss_subject3_val\n",
    "        best_classifiers['subject3'] = copy.deepcopy(classifiers['subject3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_classifiers, f'/ocean/projects/mth240012p/azhang19/lab3/classifier_ckpts/best_classifiers{weight_decay}.pth')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
